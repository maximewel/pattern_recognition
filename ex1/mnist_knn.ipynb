{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "\n",
    "data classes, general functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from enum import Enum, auto\n",
    "from dataclasses import dataclass\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_TRAIN = \"./mnist_small/train.csv\"\n",
    "KNN_TEST = \"./mnist_small/test.csv\"\n",
    "\n",
    "names = [\"label\"] + [f\"Pix {i}\" for i in range(28*28)]\n",
    "\n",
    "train_df = pd.read_csv(KNN_TRAIN, names=names)\n",
    "test_df = pd.read_csv(KNN_TEST, names=names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the data format and repartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding part\n",
    "The following sections contain the coding part of the project\n",
    "\n",
    "* Image visualization (helper tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image(mnist_array: np.array):\n",
    "    \"\"\"Visualize the given flattened image from the mnist dataset with its expected label\"\"\"\n",
    "    label = mnist_array[0]\n",
    "    image = mnist_array[1:].reshape(28, 28)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(f\"Handwritten [{label}]\") \n",
    "    plt.imshow(image, cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Distances and trivial score computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceType(Enum):\n",
    "    EUCLIDIAN = auto()\n",
    "    MANHATTAN = auto()\n",
    "\n",
    "@dataclass\n",
    "class Score():\n",
    "    \"\"\"Hold the score for a training set evalutation. Contain the score evalutation method\"\"\"\n",
    "    total: int\n",
    "    success: int\n",
    "    failures: int\n",
    "\n",
    "    accuracy: float\n",
    "\n",
    "    @classmethod\n",
    "    def compute_score(total: int, successes: int, failures: int) -> Score:\n",
    "        \"\"\"Compute the score from the given successes / failures\n",
    "        \n",
    "        Returns\n",
    "        -----\n",
    "            A score object containing the information\n",
    "        \"\"\"\n",
    "        accuracy = successes / total\n",
    "\n",
    "        return Score(total, successes, failures, accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Custom classifier, heavily coupled to test dataset but optimized for efficient tests on k via memoization of the distance map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnnClassifier:\n",
    "    \"\"\"Class encapsulating the logic of the KNN algorithm\"\"\"\n",
    "    #Work with arrays to be more efficient\n",
    "    labels: np.array\n",
    "    data: np.array\n",
    "    test_set: np.array\n",
    "\n",
    "    memoization_distancemap: dict[DistanceType, List[np.array]]\n",
    "\n",
    "    def __init__(self, train_df: pd.DataFrame, test_df: pd.DataFrame) -> None:\n",
    "        \"\"\"Init the KNN classifier with the training and testing dataset\"\"\"\n",
    "        self.train(train_df)\n",
    "        self.test_set = test_df.to_numpy()\n",
    "        self.memoization_distancemap = {dt.value: {} for dt in DistanceType}\n",
    "\n",
    "    ### Distance management ###\n",
    "    def distance_function(self, distance: DistanceType) -> callable:\n",
    "        match distance:\n",
    "            case DistanceType.MANHATTAN:\n",
    "                return self.manhattan_distance_matrix\n",
    "            case DistanceType.EUCLIDIAN:\n",
    "                return self.euclidian_distance_matrix\n",
    "            case _:\n",
    "                return NotImplementedError(f\"Distance function {distance} not known/supported\")\n",
    "\n",
    "    def euclidian_distance_matrix(self, image: np.array):\n",
    "        \"\"\"Compute the distance as the difference in intensity level pixel-wise between the input image and the classifier training data\"\"\"\n",
    "        #use numpy functions as they are made to be efficient with vecotrized input\n",
    "        return np.sqrt(np.sum(np.power(np.subtract(image, self.data), 2), axis=1))\n",
    "\n",
    "    def manhattan_distance_matrix(self, image: np.array):\n",
    "        \"\"\"Compute the distance as the difference in intensity level pixel-wise between the input image and the classifier training data\"\"\"\n",
    "        #use numpy functions as they are made to be efficient with vecotrized input\n",
    "        return np.sum(np.abs(np.subtract(image, self.data)), axis=1)\n",
    "\n",
    "    def train(self, train_df: pd.DataFrame):\n",
    "        \"\"\"Train this KNN classifier with the given dataset\"\"\"\n",
    "        #Assume MNIST: Label as first byte, image as the rest\n",
    "        self.labels = train_df.loc[:, 'label']\n",
    "        self.data = train_df.drop(['label'], axis=1, inplace=False).to_numpy()\n",
    "        print(f\"KNN prepared with {len(self.data)} data\")\n",
    "\n",
    "    def optimize_dataset(self) -> None:\n",
    "        \"\"\"Optimize the internal classifier dataset in two rounds - eliminating redundancy inforation and removing outliers.\n",
    "        Further classifications are done using the new dataset.\"\"\"\n",
    "        print(f\"Performing condensation from dataset of {len(self.data)} elements...\")\n",
    "        self.condense()\n",
    "        print(f\"Dataset now has {len(self.data)} elements\")\n",
    "\n",
    "    def condense(self) -> None:\n",
    "        \"\"\"Reduce redundancy at little cost. In-place on the training dataset of the classifier\"\"\"\n",
    "        working_set = [(i,data) for i,data in enumerate(self.data)] #working set of (index, array)\n",
    "        working_set = working_set[1:] #Remove first element, as first element init the new result set\n",
    "        initial_labels = self.labels #Keep expected labels\n",
    "        #Init new dataset with first item\n",
    "        self.labels = self.labels[:1]\n",
    "        result_set = self.data[:1]\n",
    "        self.data = result_set\n",
    "\n",
    "        #Assume default distance\n",
    "        distance = DistanceType.MANHATTAN\n",
    "        \n",
    "        print(f\"Starting condensation\")\n",
    "        change = True\n",
    "        while change:\n",
    "            change = False\n",
    "\n",
    "            #Do a 1-NN on ourself with the dataset result, if wrong, move x from working dataset to result\n",
    "            indexes_to_delete = []\n",
    "            print(F\"New iteration of the working set\")\n",
    "            i = 1\n",
    "            for (original_index, array) in working_set:\n",
    "                print(f\"\\rWorking set item {i:4}/{len(working_set)}\", end = \"\")\n",
    "                i+=1\n",
    "                expected_label = initial_labels[original_index]\n",
    "                classified_label = self.classify_single(array, None, distance, k=1, avoid_memoization=True)\n",
    "                if classified_label != expected_label:\n",
    "                    #If the 1-k classification is not correct, switch the image from working set to data set as it is significant\n",
    "                    indexes_to_delete.append(original_index) #Keep index to delete, don't delete on list while looping on it\n",
    "                    self.data: np.ndarray\n",
    "                    self.data = np.append(self.data, [array], axis=0)\n",
    "                    self.labels = np.append(self.labels, expected_label)\n",
    "                    change = True\n",
    "            print()\n",
    "\n",
    "            if change:\n",
    "                print(f\"Changes during iteration detected - {len(indexes_to_delete)} items switched to result set\")\n",
    "                working_set = [(original_index, array) for (original_index, array) in working_set if original_index not in indexes_to_delete]\n",
    "        print(f\"No change detected, condensation is over\")\n",
    "                \n",
    "    def classify_single_verbose(self, image_array: np.array, k: int, distance: DistanceType = DistanceType.EUCLIDIAN) -> None:\n",
    "        \"\"\"Classify an image by performing the KNN on the training dataset. \n",
    "        Don't return anything, focus on displaying steps to verify function execution\"\"\"\n",
    "        #Assume the MNIST format, extract expected label\n",
    "        distance_fct = self.distance_function(distance)\n",
    "        expected_label = image_array[0]\n",
    "        print(f\"Trying to correctly classify image with expected label [{expected_label}]\")\n",
    "        image = image_array[:1]\n",
    "\n",
    "        print(f\"Computing distances...\")\n",
    "        #Compute distance over each DF line\n",
    "        distances = distance_fct(image)\n",
    "        print(f\"Extract of distances: {distances[:15]}\")\n",
    "\n",
    "        #extract best class amongst distances\n",
    "        #Sort distances\n",
    "        sorted_indexes = np.argsort(distances)\n",
    "        dist_classes = [(distances[ind], self.labels[ind]) for ind in sorted_indexes[:20]]\n",
    "        print(f\"Found best distance-classes: {dist_classes}\")\n",
    "\n",
    "        #Extract sorted label of the k-neighbourhood from distances\n",
    "        neighbourhood = [self.labels[ind] for ind in sorted_indexes[:k]]\n",
    "        #count label frequency\n",
    "        sorted_freq_labels = Counter(neighbourhood).most_common() #List of tuple (label, count) sorted by the count\n",
    "        print(f\"Most common occurences: {sorted_freq_labels}\")\n",
    "\n",
    "        #In case of tie: fallback to K=1\n",
    "        if len(sorted_freq_labels) > 1 and sorted_freq_labels[0][1] == sorted_freq_labels[1][1]:\n",
    "            classified_label = self.labels[sorted_indexes[0]]\n",
    "            print(f\"Tie between {sorted_freq_labels[0][0]} and {sorted_freq_labels[1][0]}, selecting closest {classified_label}\")\n",
    "        #else simply take most common\n",
    "        else:\n",
    "            classified_label = sorted_freq_labels[0][0]\n",
    "            print(f\"Selecting {classified_label}\")\n",
    "\n",
    "    def classify_single(self, image_array: np.array, test_index: int, distance_type: DistanceType, k: int, avoid_memoization: bool = False) -> int:\n",
    "        \"\"\"Classify an image by performing the KNN on the training dataset. \n",
    "\n",
    "        Arguments\n",
    "        ----\n",
    "            image_array: The image to classify from the test set\n",
    "            i: test_index\n",
    "         \n",
    "        Returns\n",
    "        -----\n",
    "            The classified label\n",
    "        \"\"\"\n",
    "        #Compute distance over each DF line\n",
    "        #Add memoization: Keep distances if possible, assume always same test input\n",
    "        if avoid_memoization:\n",
    "            distance_fct = self.distance_function(distance_type)\n",
    "            distances = distance_fct(image_array)\n",
    "        else:\n",
    "            try:\n",
    "                distances = self.memoization_distancemap[distance_type.value][test_index]\n",
    "            except KeyError:\n",
    "                distance_fct = self.distance_function(distance_type)\n",
    "                distances = distance_fct(image_array)\n",
    "                self.memoization_distancemap[distance_type.value][test_index] = distances\n",
    "\n",
    "        #extract best class amongst distances\n",
    "        #Sort distances\n",
    "        sorted_indexes = np.argsort(distances)\n",
    "        #Extract sorted label of the k-neighbourhood from distances\n",
    "        neighbourhood = [self.labels[ind] for ind in sorted_indexes[:k]]\n",
    "        #count label frequency\n",
    "        sorted_freq_labels = Counter(neighbourhood).most_common() #List of tuple (label, count) sorted by the count\n",
    "\n",
    "        #In case of tie: fallback to K=1\n",
    "        if len(sorted_freq_labels) > 1 and sorted_freq_labels[0][1] == sorted_freq_labels[1][1]:\n",
    "            classified_label = self.labels[sorted_indexes[0]]\n",
    "        #else simply take most common\n",
    "        else:\n",
    "            classified_label = sorted_freq_labels[0][0]\n",
    "        \n",
    "        return classified_label\n",
    "    \n",
    "    def precompute_distances(self, distance_type: DistanceType) -> None:\n",
    "        \"\"\"Precompute the distances in order to have very fast KNN classification later on\n",
    "        \n",
    "        Args\n",
    "        -----\n",
    "            test_dataset: A pd dataframe containing images formated as the mnist dataset, with the label as the first byte\n",
    "        \"\"\"\n",
    "        distance_fct = self.distance_function(distance_type)\n",
    "        for i, test_array in enumerate(self.test_set):\n",
    "            image_to_test = test_array[1:]\n",
    "            distances = distance_fct(image_to_test)\n",
    "            self.memoization_distancemap[distance_type.value][i] = distances\n",
    "\n",
    "    def classify_dataset(self, distance: DistanceType, k: int) -> Score:\n",
    "        \"\"\"Classify each item on the test dataset and yields an evaluation score\n",
    "        \n",
    "        Args\n",
    "        -----\n",
    "            test_dataset: A pd dataframe containing images formated as the mnist dataset, with the label as the first byte\n",
    "\n",
    "        Returns\n",
    "        ----\n",
    "            A score object\n",
    "        \"\"\"\n",
    "        successes = 0\n",
    "        total = len(self.test_set)\n",
    "        \n",
    "        for i, test_array in enumerate(self.test_set):\n",
    "            expected_label = test_array[0]\n",
    "            image_to_test = test_array[1:]\n",
    "            classified_label = self.classify_single(image_to_test, i, distance, k)\n",
    "            if expected_label == classified_label:\n",
    "                successes += 1\n",
    "        \n",
    "        failures = total - successes\n",
    "        accuracy = successes / total\n",
    "\n",
    "        return Score(successes+failures, successes, failures, accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Test\n",
    "First, let's try our solution and see with a few numbers if the mecanism is in place with one image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnClassifier = KnnClassifier(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = test_df.sample().to_numpy()[0]\n",
    "visualize_image(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnClassifier.classify_single_verbose(test_image, 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now do the whole test dataset once\n",
    "Test the model accuracy with different values of k, with or without condensation (reduction of the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Classifying dataset with K=5\")\n",
    "score = knnClassifier.classify_dataset(DistanceType.EUCLIDIAN, k=5)\n",
    "print(f\"Correct predictions: {score.success}/{score.total}, accuracy of {score.accuracy:.2}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy of your classification for K = {1, 3, 5, 10, 15} using the best distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_k(distance: DistanceType, optimize: bool) -> None:\n",
    "    knnClass = KnnClassifier(train_df, test_df)\n",
    "    \n",
    "    if optimize:\n",
    "        knnClass.optimize_dataset()\n",
    "\n",
    "    print(f\"Precomputing distances...\")\n",
    "    knnClass.precompute_distances(distance)\n",
    "    print(f\"Distance map complete\")\n",
    "\n",
    "    for k in [1, 3, 5, 10, 15]:\n",
    "        print(f\"Evaluating for k={k}...\")\n",
    "        score: Score = knnClass.classify_dataset(distance, k)\n",
    "        print(f\"For k={k}, score is {score.accuracy}% ({score.success}/{score.total})\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test all K on raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for distance in DistanceType:\n",
    "    print(f\"Evaluating distance {distance.name}\")\n",
    "    evaluate_on_k(distance, False)\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test all K on condensated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for distance in DistanceType:\n",
    "    print(f\"Evaluating distance {distance.name}\")\n",
    "    evaluate_on_k(distance, True)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1f9fa42d969f5652b35c3c14b4f0a805b070f66d2c21805d2c1033e31e4deb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
