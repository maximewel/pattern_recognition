{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "\n",
    "data classes, general functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from enum import Enum, auto\n",
    "from dataclasses import dataclass\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_TRAIN = \"./mnist_small/train.csv\"\n",
    "KNN_TEST = \"./mnist_small/test.csv\"\n",
    "\n",
    "names = [\"label\"] + [f\"Pix {i}\" for i in range(28*28)]\n",
    "\n",
    "train_df = pd.read_csv(KNN_TRAIN, names=names)\n",
    "test_df = pd.read_csv(KNN_TEST, names=names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the data format and repartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Pix 0</th>\n",
       "      <th>Pix 1</th>\n",
       "      <th>Pix 2</th>\n",
       "      <th>Pix 3</th>\n",
       "      <th>Pix 4</th>\n",
       "      <th>Pix 5</th>\n",
       "      <th>Pix 6</th>\n",
       "      <th>Pix 7</th>\n",
       "      <th>Pix 8</th>\n",
       "      <th>...</th>\n",
       "      <th>Pix 774</th>\n",
       "      <th>Pix 775</th>\n",
       "      <th>Pix 776</th>\n",
       "      <th>Pix 777</th>\n",
       "      <th>Pix 778</th>\n",
       "      <th>Pix 779</th>\n",
       "      <th>Pix 780</th>\n",
       "      <th>Pix 781</th>\n",
       "      <th>Pix 782</th>\n",
       "      <th>Pix 783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  Pix 0  Pix 1  Pix 2  Pix 3  Pix 4  Pix 5  Pix 6  Pix 7  Pix 8  \\\n",
       "0        1      0      0      0      0      0      0      0      0      0   \n",
       "1        0      0      0      0      0      0      0      0      0      0   \n",
       "2        1      0      0      0      0      0      0      0      0      0   \n",
       "3        1      0      0      0      0      0      0      0      0      0   \n",
       "4        8      0      0      0      0      0      0      0      0      0   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "995      0      0      0      0      0      0      0      0      0      0   \n",
       "996      9      0      0      0      0      0      0      0      0      0   \n",
       "997      5      0      0      0      0      0      0      0      0      0   \n",
       "998      5      0      0      0      0      0      0      0      0      0   \n",
       "999      4      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "     ...  Pix 774  Pix 775  Pix 776  Pix 777  Pix 778  Pix 779  Pix 780  \\\n",
       "0    ...        0        0        0        0        0        0        0   \n",
       "1    ...        0        0        0        0        0        0        0   \n",
       "2    ...        0        0        0        0        0        0        0   \n",
       "3    ...        0        0        0        0        0        0        0   \n",
       "4    ...        0        0        0        0        0        0        0   \n",
       "..   ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "995  ...        0        0        0        0        0        0        0   \n",
       "996  ...        0        0        0        0        0        0        0   \n",
       "997  ...        0        0        0        0        0        0        0   \n",
       "998  ...        0        0        0        0        0        0        0   \n",
       "999  ...        0        0        0        0        0        0        0   \n",
       "\n",
       "     Pix 781  Pix 782  Pix 783  \n",
       "0          0        0        0  \n",
       "1          0        0        0  \n",
       "2          0        0        0  \n",
       "3          0        0        0  \n",
       "4          0        0        0  \n",
       "..       ...      ...      ...  \n",
       "995        0        0        0  \n",
       "996        0        0        0  \n",
       "997        0        0        0  \n",
       "998        0        0        0  \n",
       "999        0        0        0  \n",
       "\n",
       "[1000 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Pix 0</th>\n",
       "      <th>Pix 1</th>\n",
       "      <th>Pix 2</th>\n",
       "      <th>Pix 3</th>\n",
       "      <th>Pix 4</th>\n",
       "      <th>Pix 5</th>\n",
       "      <th>Pix 6</th>\n",
       "      <th>Pix 7</th>\n",
       "      <th>Pix 8</th>\n",
       "      <th>...</th>\n",
       "      <th>Pix 774</th>\n",
       "      <th>Pix 775</th>\n",
       "      <th>Pix 776</th>\n",
       "      <th>Pix 777</th>\n",
       "      <th>Pix 778</th>\n",
       "      <th>Pix 779</th>\n",
       "      <th>Pix 780</th>\n",
       "      <th>Pix 781</th>\n",
       "      <th>Pix 782</th>\n",
       "      <th>Pix 783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  Pix 0  Pix 1  Pix 2  Pix 3  Pix 4  Pix 5  Pix 6  Pix 7  Pix 8  \\\n",
       "0        5      0      0      0      0      0      0      0      0      0   \n",
       "1        8      0      0      0      0      0      0      0      0      0   \n",
       "2        1      0      0      0      0      0      0      0      0      0   \n",
       "3        6      0      0      0      0      0      0      0      0      0   \n",
       "4        1      0      0      0      0      0      0      0      0      0   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "995      5      0      0      0      0      0      0      0      0      0   \n",
       "996      1      0      0      0      0      0      0      0      0      0   \n",
       "997      0      0      0      0      0      0      0      0      0      0   \n",
       "998      3      0      0      0      0      0      0      0      0      0   \n",
       "999      8      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "     ...  Pix 774  Pix 775  Pix 776  Pix 777  Pix 778  Pix 779  Pix 780  \\\n",
       "0    ...        0        0        0        0        0        0        0   \n",
       "1    ...        0        0        0        0        0        0        0   \n",
       "2    ...        0        0        0        0        0        0        0   \n",
       "3    ...        0        0        0        0        0        0        0   \n",
       "4    ...        0        0        0        0        0        0        0   \n",
       "..   ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "995  ...        0        0        0        0        0        0        0   \n",
       "996  ...        0        0        0        0        0        0        0   \n",
       "997  ...        0        0        0        0        0        0        0   \n",
       "998  ...        0        0        0        0        0        0        0   \n",
       "999  ...        0        0        0        0        0        0        0   \n",
       "\n",
       "     Pix 781  Pix 782  Pix 783  \n",
       "0          0        0        0  \n",
       "1          0        0        0  \n",
       "2          0        0        0  \n",
       "3          0        0        0  \n",
       "4          0        0        0  \n",
       "..       ...      ...      ...  \n",
       "995        0        0        0  \n",
       "996        0        0        0  \n",
       "997        0        0        0  \n",
       "998        0        0        0  \n",
       "999        0        0        0  \n",
       "\n",
       "[1000 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding part\n",
    "The following sections contain the coding part of the project\n",
    "\n",
    "* Image visualization (helper tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image(mnist_array: np.array):\n",
    "    \"\"\"Visualize the given flattened image from the mnist dataset with its expected label\"\"\"\n",
    "    label = mnist_array[0]\n",
    "    image = mnist_array[1:].reshape(28, 28)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(f\"Handwritten [{label}]\") \n",
    "    plt.imshow(image, cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Distances and trivial score computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceType(Enum):\n",
    "    EUCLIDIAN = auto()\n",
    "    MANHATTAN = auto()\n",
    "\n",
    "@dataclass\n",
    "class Score():\n",
    "    \"\"\"Hold the score for a training set evalutation. Contain the score evalutation method\"\"\"\n",
    "    total: int\n",
    "    success: int\n",
    "    failures: int\n",
    "\n",
    "    accuracy: float\n",
    "\n",
    "    @classmethod\n",
    "    def compute_score(total: int, successes: int, failures: int) -> Score:\n",
    "        \"\"\"Compute the score from the given successes / failures\n",
    "        \n",
    "        Returns\n",
    "        -----\n",
    "            A score object containing the information\n",
    "        \"\"\"\n",
    "        accuracy = successes / total\n",
    "\n",
    "        return Score(total, successes, failures, accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Custom classifier, heavily coupled to test dataset but optimized for efficient tests on k via memoization of the distance map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnnClassifier:\n",
    "    \"\"\"Class encapsulating the logic of the KNN algorithm\"\"\"\n",
    "    #Work with arrays to be more efficient\n",
    "    labels: np.array\n",
    "    data: np.array\n",
    "    test_set: np.array\n",
    "\n",
    "    memoization_distancemap: dict[DistanceType, List[np.array]]\n",
    "\n",
    "    def __init__(self, train_df: pd.DataFrame, test_df: pd.DataFrame) -> None:\n",
    "        \"\"\"Init the KNN classifier with the training and testing dataset\"\"\"\n",
    "        self.train(train_df)\n",
    "        self.test_set = test_df.to_numpy()\n",
    "        self.memoization_distancemap = {dt.value: {} for dt in DistanceType}\n",
    "\n",
    "    ### Distance management ###\n",
    "    def distance_function(self, distance: DistanceType) -> callable:\n",
    "        match distance:\n",
    "            case DistanceType.MANHATTAN:\n",
    "                return self.manhattan_distance_matrix\n",
    "            case DistanceType.EUCLIDIAN:\n",
    "                return self.euclidian_distance_matrix\n",
    "            case _:\n",
    "                return NotImplementedError(f\"Distance function {distance} not known/supported\")\n",
    "\n",
    "    def euclidian_distance_matrix(self, image: np.array):\n",
    "        \"\"\"Compute the distance as the difference in intensity level pixel-wise between the input image and the classifier training data\"\"\"\n",
    "        #use numpy functions as they are made to be efficient with vecotrized input\n",
    "        return np.sqrt(np.sum(np.power(np.subtract(image, self.data), 2), axis=1))\n",
    "\n",
    "    def manhattan_distance_matrix(self, image: np.array):\n",
    "        \"\"\"Compute the distance as the difference in intensity level pixel-wise between the input image and the classifier training data\"\"\"\n",
    "        #use numpy functions as they are made to be efficient with vecotrized input\n",
    "        return np.sum(np.abs(np.subtract(image, self.data)), axis=1)\n",
    "\n",
    "    def train(self, train_df: pd.DataFrame):\n",
    "        \"\"\"Train this KNN classifier with the given dataset\"\"\"\n",
    "        #Assume MNIST: Label as first byte, image as the rest\n",
    "        self.labels = train_df.loc[:, 'label']\n",
    "        self.data = train_df.drop(['label'], axis=1, inplace=False).to_numpy()\n",
    "        print(f\"KNN prepared with {len(self.data)} data\")\n",
    "\n",
    "    def optimize_dataset(self) -> None:\n",
    "        \"\"\"Optimize the internal classifier dataset in two rounds - eliminating redundancy inforation and removing outliers.\n",
    "        Further classifications are done using the new dataset.\"\"\"\n",
    "        print(f\"Performing condensation from dataset of {len(self.data)} elements...\")\n",
    "        self.condense()\n",
    "        print(f\"Dataset now has {len(self.data)} elements\")\n",
    "\n",
    "    def condense(self) -> None:\n",
    "        \"\"\"Reduce redundancy at little cost. In-place on the training dataset of the classifier\"\"\"\n",
    "        working_set = [(i,data) for i,data in enumerate(self.data)] #working set of (index, array)\n",
    "        working_set = working_set[1:] #Remove first element, as first element init the new result set\n",
    "        initial_labels = self.labels #Keep expected labels\n",
    "        #Init new dataset with first item\n",
    "        self.labels = self.labels[:1]\n",
    "        result_set = self.data[:1]\n",
    "        self.data = result_set\n",
    "\n",
    "        #Assume default distance\n",
    "        distance = DistanceType.MANHATTAN\n",
    "        \n",
    "        print(f\"Starting condensation\")\n",
    "        change = True\n",
    "        while change:\n",
    "            change = False\n",
    "\n",
    "            #Do a 1-NN on ourself with the dataset result, if wrong, move x from working dataset to result\n",
    "            indexes_to_delete = []\n",
    "            print(F\"New iteration of the working set\")\n",
    "            i = 1\n",
    "            for (original_index, array) in working_set:\n",
    "                print(f\"\\rWorking set item {i:4}/{len(working_set)}\", end = \"\")\n",
    "                i+=1\n",
    "                expected_label = initial_labels[original_index]\n",
    "                classified_label = self.classify_single(array, None, distance, k=1, avoid_memoization=True)\n",
    "                if classified_label != expected_label:\n",
    "                    #If the 1-k classification is not correct, switch the image from working set to data set as it is significant\n",
    "                    indexes_to_delete.append(original_index) #Keep index to delete, don't delete on list while looping on it\n",
    "                    self.data: np.ndarray\n",
    "                    self.data = np.append(self.data, [array], axis=0)\n",
    "                    self.labels = np.append(self.labels, expected_label)\n",
    "                    change = True\n",
    "            print()\n",
    "\n",
    "            if change:\n",
    "                print(f\"Changes during iteration detected - {len(indexes_to_delete)} items switched to result set\")\n",
    "                working_set = [(original_index, array) for (original_index, array) in working_set if original_index not in indexes_to_delete]\n",
    "        print(f\"No change detected, condensation is over\")\n",
    "                \n",
    "    def classify_single_verbose(self, image_array: np.array, k: int, distance: DistanceType = DistanceType.EUCLIDIAN) -> None:\n",
    "        \"\"\"Classify an image by performing the KNN on the training dataset. \n",
    "        Don't return anything, focus on displaying steps to verify function execution\"\"\"\n",
    "        #Assume the MNIST format, extract expected label\n",
    "        distance_fct = self.distance_function(distance)\n",
    "        expected_label = image_array[0]\n",
    "        print(f\"Trying to correctly classify image with expected label [{expected_label}]\")\n",
    "        image = image_array[:1]\n",
    "\n",
    "        print(f\"Computing distances...\")\n",
    "        #Compute distance over each DF line\n",
    "        distances = distance_fct(image)\n",
    "        print(f\"Extract of distances: {distances[:15]}\")\n",
    "\n",
    "        #extract best class amongst distances\n",
    "        #Sort distances\n",
    "        sorted_indexes = np.argsort(distances)\n",
    "        dist_classes = [(distances[ind], self.labels[ind]) for ind in sorted_indexes[:20]]\n",
    "        print(f\"Found best distance-classes: {dist_classes}\")\n",
    "\n",
    "        #Extract sorted label of the k-neighbourhood from distances\n",
    "        neighbourhood = [self.labels[ind] for ind in sorted_indexes[:k]]\n",
    "        #count label frequency\n",
    "        sorted_freq_labels = Counter(neighbourhood).most_common() #List of tuple (label, count) sorted by the count\n",
    "        print(f\"Most common occurences: {sorted_freq_labels}\")\n",
    "\n",
    "        #In case of tie: fallback to K=1\n",
    "        if len(sorted_freq_labels) > 1 and sorted_freq_labels[0][1] == sorted_freq_labels[1][1]:\n",
    "            classified_label = self.labels[sorted_indexes[0]]\n",
    "            print(f\"Tie between {sorted_freq_labels[0][0]} and {sorted_freq_labels[1][0]}, selecting closest {classified_label}\")\n",
    "        #else simply take most common\n",
    "        else:\n",
    "            classified_label = sorted_freq_labels[0][0]\n",
    "            print(f\"Selecting {classified_label}\")\n",
    "\n",
    "    def classify_single(self, image_array: np.array, test_index: int, distance_type: DistanceType, k: int, avoid_memoization: bool = False) -> int:\n",
    "        \"\"\"Classify an image by performing the KNN on the training dataset. \n",
    "\n",
    "        Arguments\n",
    "        ----\n",
    "            image_array: The image to classify from the test set\n",
    "            i: test_index\n",
    "         \n",
    "        Returns\n",
    "        -----\n",
    "            The classified label\n",
    "        \"\"\"\n",
    "        #Compute distance over each DF line\n",
    "        #Add memoization: Keep distances if possible, assume always same test input\n",
    "        if avoid_memoization:\n",
    "            distance_fct = self.distance_function(distance_type)\n",
    "            distances = distance_fct(image_array)\n",
    "        else:\n",
    "            try:\n",
    "                distances = self.memoization_distancemap[distance_type.value][test_index]\n",
    "            except KeyError:\n",
    "                distance_fct = self.distance_function(distance_type)\n",
    "                distances = distance_fct(image_array)\n",
    "                self.memoization_distancemap[distance_type.value][test_index] = distances\n",
    "\n",
    "        #extract best class amongst distances\n",
    "        #Sort distances\n",
    "        sorted_indexes = np.argsort(distances)\n",
    "        #Extract sorted label of the k-neighbourhood from distances\n",
    "        neighbourhood = [self.labels[ind] for ind in sorted_indexes[:k]]\n",
    "        #count label frequency\n",
    "        sorted_freq_labels = Counter(neighbourhood).most_common() #List of tuple (label, count) sorted by the count\n",
    "\n",
    "        #In case of tie: fallback to K=1\n",
    "        if len(sorted_freq_labels) > 1 and sorted_freq_labels[0][1] == sorted_freq_labels[1][1]:\n",
    "            classified_label = self.labels[sorted_indexes[0]]\n",
    "        #else simply take most common\n",
    "        else:\n",
    "            classified_label = sorted_freq_labels[0][0]\n",
    "        \n",
    "        return classified_label\n",
    "    \n",
    "    def precompute_distances(self, distance_type: DistanceType) -> None:\n",
    "        \"\"\"Precompute the distances in order to have very fast KNN classification later on\n",
    "        \n",
    "        Args\n",
    "        -----\n",
    "            test_dataset: A pd dataframe containing images formated as the mnist dataset, with the label as the first byte\n",
    "        \"\"\"\n",
    "        distance_fct = self.distance_function(distance_type)\n",
    "        for i, test_array in enumerate(self.test_set):\n",
    "            image_to_test = test_array[1:]\n",
    "            distances = distance_fct(image_to_test)\n",
    "            self.memoization_distancemap[distance_type.value][i] = distances\n",
    "\n",
    "    def classify_dataset(self, distance: DistanceType, k: int) -> Score:\n",
    "        \"\"\"Classify each item on the test dataset and yields an evaluation score\n",
    "        \n",
    "        Args\n",
    "        -----\n",
    "            test_dataset: A pd dataframe containing images formated as the mnist dataset, with the label as the first byte\n",
    "\n",
    "        Returns\n",
    "        ----\n",
    "            A score object\n",
    "        \"\"\"\n",
    "        successes = 0\n",
    "        total = len(self.test_set)\n",
    "        \n",
    "        for i, test_array in enumerate(self.test_set):\n",
    "            expected_label = test_array[0]\n",
    "            image_to_test = test_array[1:]\n",
    "            classified_label = self.classify_single(image_to_test, i, distance, k)\n",
    "            if expected_label == classified_label:\n",
    "                successes += 1\n",
    "        \n",
    "        failures = total - successes\n",
    "        accuracy = successes / total\n",
    "\n",
    "        return Score(successes+failures, successes, failures, accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Test\n",
    "First, let's try our solution and see with a few numbers if the mecanism is in place with one image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN prepared with 1000 data\n"
     ]
    }
   ],
   "source": [
    "knnClassifier = KnnClassifier(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAkMklEQVR4nO3df3RU9Z3/8dcEyAAhGQyQXxDyAxUUBE8DRJYfgkSS2GXFX6vi7gbrkaIBBaq2VEuw9Wxa2yOulsJu3ZL6A2j1VFksSw8iCUgDCpjlQHcpQSpQSJAcmYEAgSWf7x98mWVIEGeY8E7C83HO5xzm3s/n3nduLvPK/TF3PM45JwAArrAY6wIAAFcnAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCDhPWVmZPB6P/vKXv7TYOsrLy+XxeFReXt5i64imzMxMeTweeTweTZ8+PaJlzJw5M7iMbt26RblCtFUEEK64c2/ymzdvbnb+2LFjNWjQoCtcla0lS5bo5ZdfbjL9wIEDmjdvnqqqqq54TecbPXq03njjDRUVFQWnnThxQo888ogGDRokn8+nbt26aciQIfqXf/kXnT59OmT8P/7jP+qNN97Q6NGjr3TpaMU6WhcAXG3GjBmjEydOKDY2NjhtyZIl2r59u2bOnBnS98CBA3r++eeVmZmpm2+++coWep7s7Gz9wz/8Q8i0EydOaMeOHbrjjjuUmZmpmJgY/fGPf9SsWbO0adMmLVmyJNg3JydHOTk5+uCDD7R169YrXT5aKQIIuEJOnjyp2NhYxcTEqHPnztblXLbExERt3LgxZNq0adPk8/n085//XC+99JJSUlKMqkNbwCk4tAmLFy/WbbfdpqSkJHm9Xt14441auHBhk36ZmZn627/9W3300UcaPny4OnfurOzsbL3++utN+u7YsUO33XabunTpoj59+uiFF15QY2NjSJ/Zs2erR48eOv+h8TNmzJDH49Err7wSnFZbWyuPxxOs6dx1nmXLlum5555T79691bVrVwUCgSbXgMaOHavf//73+vzzz4PXSTIzM1VeXq5hw4ZJkh5++OHgvLKysuB6N23apIKCAvl8PnXt2lW33nqrNmzYEPIzzJs3Tx6PR9XV1ZoyZYq6d+8un8+nhx9+WMePHw/vF/E1ZGZmSpKOHDkS9WWjfeEICGb8fr8OHz7cZPqF1w8kaeHChRo4cKD+7u/+Th07dtSKFSv0+OOPq7GxUcXFxSF9q6urde+99+qRRx5RUVGRfvWrX2nKlCnKycnRwIEDJUk1NTUaN26c/vd//1ff+973FBcXp3/7t39Tly5dQpY1evRozZ8/Xzt27Ahel1q/fr1iYmK0fv16PfHEE8Fp0tnTa+f70Y9+pNjYWD311FNqaGgIOe12zrPPPiu/36/9+/dr/vz5kqRu3brphhtu0A9/+EPNnTtXU6dODV4/+Zu/+RtJ0ocffqjCwkLl5OSopKREMTExwaBev369hg8fHrKev//7v1dWVpZKS0u1detWvfbaa0pKStJPfvKT5n49X9upU6cUCAR04sQJbd68WT/72c+UkZGha6+99rKWi6uAA66wxYsXO0lf2QYOHBgy5vjx402Wk5+f77Kzs0OmZWRkOElu3bp1wWmHDh1yXq/Xfec73wlOmzlzppPkNm3aFNLP5/M5SW7Pnj3BaZLcL37xC+ecc0eOHHExMTHuvvvuc8nJycGxTzzxhEtMTHSNjY3OOefWrl3rJLns7OwmtZ+bt3bt2uC0b37zmy4jI6PJz/jJJ584SW7x4sUh0xsbG911113n8vPzg+s8t52ysrLc7bffHpxWUlLiJLlvfetbIcu46667XI8ePZqs80IZGRmuqKjoovOXLl0a8rsbOnSo27ZtW7N9i4qKXFxc3CXXiasDp+BgZsGCBVq9enWTNnjw4CZ9zz8yOXfkdOutt+qzzz6T3+8P6XvjjTeG3G3Vq1cv9e/fX5999llw2sqVK3XLLbeEHCX06tVLDz30UMiyevXqpQEDBmjdunWSpA0bNqhDhw56+umnVVtbq127dkk6ewQ0atQoeTyekPFFRUVNjqqioaqqSrt27dLkyZNVV1enw4cP6/Dhw6qvr9f48eO1bt26JqcTp02bFvJ69OjRqqurUyAQuKxaxo0bp9WrV+vtt9/WtGnT1KlTJ9XX11/WMnF14BQczAwfPlxDhw5tMv2aa65pcmpuw4YNKikpUWVlZZPrFn6/Xz6fL/i6b9++zS7zyy+/DL7+/PPPlZub26Rf//79m0wbPXq0Vq5cKels0AwdOlRDhw5VYmKi1q9fr+TkZP3Xf/2XJk+e3GRsVlZWk2nRcC74zr8t+kJ+v1/XXHNN8PWF2+XcvC+//FIJCQkR15KcnKzk5GRJ0r333qt//ud/1u23365du3ZxEwK+EgGEVm/37t0aP368BgwYoJdeeknp6emKjY3VypUrNX/+/CZ/6Xfo0KHZ5bgIv31+1KhR+uUvf6nPPvtM69ev1+jRo+XxeDRq1CitX79eaWlpamxsbPYzLi1x9CMp+DP/9Kc/vejt2Rd+4DPa2+Vi7r33Xj377LNavny5vv3tb0d12WhfCCC0eitWrFBDQ4P+4z/+I+Sv+LVr10a8zIyMjOBRxPl27tzZZNq5YFm9erU++eQTfe9735N09oaDhQsXKi0tTXFxccrJyYm4ngtP3V1qer9+/SRJCQkJysvLi3i9LeHEiROS1OTUKHAhrgGh1Tv3l/v5f6n7/X4tXrw44mXecccd2rhxoz7++OPgtC+++EJvvfVWk75ZWVnq3bu35s+fr9OnT2vkyJGSzgbT7t279c477+iWW25Rx46R/z0XFxfX7Bt2XFycpKa3NOfk5Khfv3762c9+pmPHjjUZ98UXX0Rcy9d1+PDhZo+eXnvtNUlq9vQqcD6OgNDqTZgwQbGxsZo4caK+/e1v69ixY/rlL3+ppKQkHTx4MKJlPvPMM3rjjTdUUFCgJ598MngbdkZGhrZt29ak/+jRo7Vs2TLddNNNwWsn3/jGNxQXF6c///nPzV7/CUdOTo5+85vfaPbs2Ro2bJi6deumiRMnql+/furevbsWLVqk+Ph4xcXFKTc3V1lZWXrttddUWFiogQMH6uGHH1bv3r3117/+VWvXrlVCQoJWrFhxWTVdyptvvqlFixZp0qRJys7O1tGjR/WHP/xBq1ev1sSJE3Xbbbe16PrR9nEEhFavf//+euedd+TxePTUU09p0aJFmjp1qp588smIl5mamqq1a9dq8ODB+vGPf6yXX35Z//RP/3TRZZ47DTdq1KjgtI4dO2rEiBEh8yP1+OOPa/LkyVq8eLEmT56sGTNmSJI6deqkX//61+rQoYOmTZumBx98UBUVFZLOfoC1srJSQ4cO1c9//nPNmDFDZWVlSklJ0axZsy6rnq9j1KhRGjx4sJYuXaonnnhCJSUlqqur00svvaTf/e53Lb5+tH0eF+0rkADalczMTI0YMUKvvvqqunTpEjwtGI76+nqdOHFCM2bM0IoVK5o9bYirD0dAAC5p2bJl6tWrl7773e9GNP7ZZ59Vr169tGzZsihXhraMIyAAX2nDhg3BO9vS09Ob/azUpfz5z3/W3r17JZ09dTl27Nholog2igACAJjgFBwAwAQBBAAwQQABAEy0ug+iNjY26sCBA4qPj7/oY0gAAK2Xc05Hjx5VWlqaYmIufpzT6gLowIEDSk9Pty4DAHCZ9u3bpz59+lx0fqs7BRcfH29dAgAgCi71ft5iAbRgwQJlZmaqc+fOys3NDXno41fhtBsAtA+Xej9vkQA691DFkpISbd26VUOGDFF+fr4OHTrUEqsDALRFLfE938OHD3fFxcXB12fOnHFpaWmutLT0kmP9fn/I98vTaDQarW02v9//le/3UT8COnXqlLZs2RLyJVkxMTHKy8tTZWVlk/4NDQ0KBAIhDQDQ/kU9gA4fPqwzZ84EvyP+nOTkZNXU1DTpX1paKp/PF2zcAQcAVwfzu+DmzJkjv98fbPv27bMuCQBwBUT9c0A9e/ZUhw4dVFtbGzK9trZWKSkpTfp7vV55vd5olwEAaOWifgQUGxurnJwcrVmzJjitsbFRa9asCX57JAAALfIkhNmzZ6uoqEhDhw7V8OHD9fLLL6u+vl4PP/xwS6wOANAGtUgA3X///friiy80d+5c1dTU6Oabb9aqVaua3JgAALh6tbovpAsEAvL5fNZlAAAuk9/vV0JCwkXnm98FBwC4OhFAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwERH6wKAljBv3ryIxvXv3z+6hUTRfffdF/aYurq6iNY1fvz4sMds3749onXh6sUREADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABM8jBTt0g033BDRuEge+Nma9erVK6Jxt99+e9hjeBgpwsUREADABAEEADAR9QCaN2+ePB5PSBswYEC0VwMAaONa5BrQwIED9cEHH/zfSjpyqQkAEKpFkqFjx45KSUlpiUUDANqJFrkGtGvXLqWlpSk7O1sPPfSQ9u7de9G+DQ0NCgQCIQ0A0P5FPYByc3NVVlamVatWaeHChdqzZ49Gjx6to0ePNtu/tLRUPp8v2NLT06NdEgCgFYp6ABUWFuq+++7T4MGDlZ+fr5UrV+rIkSP67W9/22z/OXPmyO/3B9u+ffuiXRIAoBVq8bsDunfvruuvv17V1dXNzvd6vfJ6vS1dBgCglWnxzwEdO3ZMu3fvVmpqakuvCgDQhkQ9gJ566ilVVFToL3/5i/74xz/qrrvuUocOHfTggw9Ge1UAgDYs6qfg9u/frwcffFB1dXXq1auXRo0apY0bN0b8TCoAQPvkcc456yLOFwgE5PP5rMtAGxfpdcWuXbuGPSYjIyPsMc8991zYY+6+++6wxyxbtizsMZJUXFwc9pgvv/wyonWh/fL7/UpISLjofJ4FBwAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwESLfyEdYKGhoeGKjYuJCf/vuIEDB4Y9ZsOGDWGPieShohIPFsWVwREQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAET8MGLtN9990X9pj+/fuHPeb73/9+2GN4qjVaM46AAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmOBhpMBlSk9PD3vMX//617DH/P73vw97DNCacQQEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADAhMc556yLOF8gEJDP57MuA/jaEhMTwx6zb9++sMeMHDky7DFVVVVhjwGixe/3KyEh4aLzOQICAJgggAAAJsIOoHXr1mnixIlKS0uTx+PRe++9FzLfOae5c+cqNTVVXbp0UV5ennbt2hWtegEA7UTYAVRfX68hQ4ZowYIFzc5/8cUX9corr2jRokXatGmT4uLilJ+fr5MnT152sQCA9iPsb0QtLCxUYWFhs/Occ3r55Zf13HPP6c4775Qkvf7660pOTtZ7772nBx544PKqBQC0G1G9BrRnzx7V1NQoLy8vOM3n8yk3N1eVlZXNjmloaFAgEAhpAID2L6oBVFNTI0lKTk4OmZ6cnBycd6HS0lL5fL5gS09Pj2ZJAIBWyvwuuDlz5sjv9wdbJJ+PAAC0PVENoJSUFElSbW1tyPTa2trgvAt5vV4lJCSENABA+xfVAMrKylJKSorWrFkTnBYIBLRp0yaNGDEimqsCALRxYd8Fd+zYMVVXVwdf79mzR1VVVUpMTFTfvn01c+ZMvfDCC7ruuuuUlZWlH/zgB0pLS9OkSZOiWTcAoI0LO4A2b96scePGBV/Pnj1bklRUVKSysjI988wzqq+v19SpU3XkyBGNGjVKq1atUufOnaNXNQCgzeNhpICBuXPnhj3m/D/8vq6CgoKwx0hnPx4BXC4eRgoAaJUIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACZ4GjbQRqxcuTLsMb/61a8iWtc777wT0TjgfDwNGwDQKhFAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADDR0boAAF/Pq6++GvaY1157LaJ1VVdXhz2mqqoqonXh6sUREADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABM8jBRoI/7zP/8z7DFbt26NaF3jxo0LewwPI0W4OAICAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABggoeRAu3Y3r17Ixr3zDPPhD3mrbfeCnvMoUOHwh6D9oMjIACACQIIAGAi7ABat26dJk6cqLS0NHk8Hr333nsh86dMmSKPxxPSCgoKolUvAKCdCDuA6uvrNWTIEC1YsOCifQoKCnTw4MFgW7p06WUVCQBof8K+CaGwsFCFhYVf2cfr9SolJSXiogAA7V+LXAMqLy9XUlKS+vfvr8cee0x1dXUX7dvQ0KBAIBDSAADtX9QDqKCgQK+//rrWrFmjn/zkJ6qoqFBhYaHOnDnTbP/S0lL5fL5gS09Pj3ZJAIBWKOqfA3rggQeC/77ppps0ePBg9evXT+Xl5Ro/fnyT/nPmzNHs2bODrwOBACEEAFeBFr8NOzs7Wz179lR1dXWz871erxISEkIaAKD9a/EA2r9/v+rq6pSamtrSqwIAtCFhn4I7duxYyNHMnj17VFVVpcTERCUmJur555/XPffco5SUFO3evVvPPPOMrr32WuXn50e1cABA2xZ2AG3evFnjxo0Lvj53/aaoqEgLFy7Utm3b9Otf/1pHjhxRWlqaJkyYoB/96Efyer3RqxoA0OaFHUBjx46Vc+6i8//whz9cVkEA7CUnJ4c9Jj4+PuwxPIz06saz4AAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJqL+ldwAWo/ExMSIxtXX14c9pqGhIaJ14erFERAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATPIwUaCPi4+PDHlNYWBjRuv70pz+FPWb//v0RrQtXL46AAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmOBhpEAb8c4774Q9JiEhIaJ17dixI6JxQDg4AgIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCh5Hiirr++uvDHvPmm2+GPWbq1Klhj5GkqqqqsMfcfPPNYY957rnnwh4zfvz4sMdE6pNPPrli68LViyMgAIAJAggAYCKsACotLdWwYcMUHx+vpKQkTZo0STt37gzpc/LkSRUXF6tHjx7q1q2b7rnnHtXW1ka1aABA2xdWAFVUVKi4uFgbN27U6tWrdfr0aU2YMEH19fXBPrNmzdKKFSv09ttvq6KiQgcOHNDdd98d9cIBAG1bWDchrFq1KuR1WVmZkpKStGXLFo0ZM0Z+v1///u//riVLlui2226TJC1evFg33HCDNm7cqFtuuSV6lQMA2rTLugbk9/slSYmJiZKkLVu26PTp08rLywv2GTBggPr27avKyspml9HQ0KBAIBDSAADtX8QB1NjYqJkzZ2rkyJEaNGiQJKmmpkaxsbHq3r17SN/k5GTV1NQ0u5zS0lL5fL5gS09Pj7QkAEAbEnEAFRcXa/v27Vq2bNllFTBnzhz5/f5g27dv32UtDwDQNkT0QdTp06fr/fff17p169SnT5/g9JSUFJ06dUpHjhwJOQqqra1VSkpKs8vyer3yer2RlAEAaMPCOgJyzmn69Ol699139eGHHyorKytkfk5Ojjp16qQ1a9YEp+3cuVN79+7ViBEjolMxAKBdCOsIqLi4WEuWLNHy5csVHx8fvK7j8/nUpUsX+Xw+PfLII5o9e7YSExOVkJCgGTNmaMSIEdwBBwAIEVYALVy4UJI0duzYkOmLFy/WlClTJEnz589XTEyM7rnnHjU0NCg/P1+/+MUvolIsAKD98DjnnHUR5wsEAvL5fNZloIUMHz487DEfffRR2GN27NgR9hhJEX0M4MYbbwx7TM+ePcMeE8l/1UgfKjpmzJiwxzQ0NES0LrRffr9fCQkJF53Ps+AAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYi+kZUIFIff/xx2GNeeOGFsMd861vfCnuMJA0ZMiSiceE6depU2GM2bNgQ9phHH3007DEST7bGlcEREADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMe55yzLuJ8gUBAPp/Pugy0cbGxsRGNW7JkSdhjdu3aFfaYBQsWhD1m//79YY8BLPn9fiUkJFx0PkdAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATPAwUgBAi+BhpACAVokAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACbCCqDS0lINGzZM8fHxSkpK0qRJk7Rz586QPmPHjpXH4wlp06ZNi2rRAIC2L6wAqqioUHFxsTZu3KjVq1fr9OnTmjBhgurr60P6Pfroozp48GCwvfjii1EtGgDQ9nUMp/OqVatCXpeVlSkpKUlbtmzRmDFjgtO7du2qlJSU6FQIAGiXLusakN/vlyQlJiaGTH/rrbfUs2dPDRo0SHPmzNHx48cvuoyGhgYFAoGQBgC4CrgInTlzxn3zm990I0eODJn+r//6r27VqlVu27Zt7s0333S9e/d2d91110WXU1JS4iTRaDQarZ01v9//lTkScQBNmzbNZWRkuH379n1lvzVr1jhJrrq6utn5J0+edH6/P9j27dtnvtFoNBqNdvntUgEU1jWgc6ZPn673339f69atU58+fb6yb25uriSpurpa/fr1azLf6/XK6/VGUgYAoA0LK4Ccc5oxY4beffddlZeXKysr65JjqqqqJEmpqakRFQgAaJ/CCqDi4mItWbJEy5cvV3x8vGpqaiRJPp9PXbp00e7du7VkyRLdcccd6tGjh7Zt26ZZs2ZpzJgxGjx4cIv8AACANiqc6z66yHm+xYsXO+ec27t3rxszZoxLTEx0Xq/XXXvtte7pp5++5HnA8/n9fvPzljQajUa7/Hap937P/w+WViMQCMjn81mXAQC4TH6/XwkJCRedz7PgAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmWl0AOeesSwAARMGl3s9bXQAdPXrUugQAQBRc6v3c41rZIUdjY6MOHDig+Ph4eTyekHmBQEDp6enat2+fEhISjCq0x3Y4i+1wFtvhLLbDWa1hOzjndPToUaWlpSkm5uLHOR2vYE1fS0xMjPr06fOVfRISEq7qHewctsNZbIez2A5nsR3Ost4OPp/vkn1a3Sk4AMDVgQACAJhoUwHk9XpVUlIir9drXYoptsNZbIez2A5nsR3OakvbodXdhAAAuDq0qSMgAED7QQABAEwQQAAAEwQQAMAEAQQAMNFmAmjBggXKzMxU586dlZubq48//ti6pCtu3rx58ng8IW3AgAHWZbW4devWaeLEiUpLS5PH49F7770XMt85p7lz5yo1NVVdunRRXl6edu3aZVNsC7rUdpgyZUqT/aOgoMCm2BZSWlqqYcOGKT4+XklJSZo0aZJ27twZ0ufkyZMqLi5Wjx491K1bN91zzz2qra01qrhlfJ3tMHbs2Cb7w7Rp04wqbl6bCKDf/OY3mj17tkpKSrR161YNGTJE+fn5OnTokHVpV9zAgQN18ODBYPvoo4+sS2px9fX1GjJkiBYsWNDs/BdffFGvvPKKFi1apE2bNikuLk75+fk6efLkFa60ZV1qO0hSQUFByP6xdOnSK1hhy6uoqFBxcbE2btyo1atX6/Tp05owYYLq6+uDfWbNmqUVK1bo7bffVkVFhQ4cOKC7777bsOro+zrbQZIeffTRkP3hxRdfNKr4IlwbMHz4cFdcXBx8febMGZeWluZKS0sNq7rySkpK3JAhQ6zLMCXJvfvuu8HXjY2NLiUlxf30pz8NTjty5Ijzer1u6dKlBhVeGRduB+ecKyoqcnfeeadJPVYOHTrkJLmKigrn3NnffadOndzbb78d7PPf//3fTpKrrKy0KrPFXbgdnHPu1ltvdU8++aRdUV9Dqz8COnXqlLZs2aK8vLzgtJiYGOXl5amystKwMhu7du1SWlqasrOz9dBDD2nv3r3WJZnas2ePampqQvYPn8+n3Nzcq3L/KC8vV1JSkvr376/HHntMdXV11iW1KL/fL0lKTEyUJG3ZskWnT58O2R8GDBigvn37tuv94cLtcM5bb72lnj17atCgQZozZ46OHz9uUd5FtbqnYV/o8OHDOnPmjJKTk0OmJycn63/+53+MqrKRm5ursrIy9e/fXwcPHtTzzz+v0aNHa/v27YqPj7cuz0RNTY0kNbt/nJt3tSgoKNDdd9+trKws7d69W9///vdVWFioyspKdejQwbq8qGtsbNTMmTM1cuRIDRo0SNLZ/SE2Nlbdu3cP6due94fmtoMkTZ48WRkZGUpLS9O2bdv03e9+Vzt37tTvfvc7w2pDtfoAwv8pLCwM/nvw4MHKzc1VRkaGfvvb3+qRRx4xrAytwQMPPBD890033aTBgwerX79+Ki8v1/jx4w0raxnFxcXavn37VXEd9KtcbDtMnTo1+O+bbrpJqampGj9+vHbv3q1+/fpd6TKb1epPwfXs2VMdOnRochdLbW2tUlJSjKpqHbp3767rr79e1dXV1qWYObcPsH80lZ2drZ49e7bL/WP69Ol6//33tXbt2pDvD0tJSdGpU6d05MiRkP7tdX+42HZoTm5uriS1qv2h1QdQbGyscnJytGbNmuC0xsZGrVmzRiNGjDCszN6xY8e0e/dupaamWpdiJisrSykpKSH7RyAQ0KZNm676/WP//v2qq6trV/uHc07Tp0/Xu+++qw8//FBZWVkh83NyctSpU6eQ/WHnzp3au3dvu9ofLrUdmlNVVSVJrWt/sL4L4utYtmyZ83q9rqyszP3pT39yU6dOdd27d3c1NTXWpV1R3/nOd1x5ebnbs2eP27Bhg8vLy3M9e/Z0hw4dsi6tRR09etR9+umn7tNPP3WS3EsvveQ+/fRT9/nnnzvnnPvxj3/sunfv7pYvX+62bdvm7rzzTpeVleVOnDhhXHl0fdV2OHr0qHvqqadcZWWl27Nnj/vggw/cN77xDXfddde5kydPWpceNY899pjz+XyuvLzcHTx4MNiOHz8e7DNt2jTXt29f9+GHH7rNmze7ESNGuBEjRhhWHX2X2g7V1dXuhz/8odu8ebPbs2ePW758ucvOznZjxowxrjxUmwgg55x79dVXXd++fV1sbKwbPny427hxo3VJV9z999/vUlNTXWxsrOvdu7e7//77XXV1tXVZLW7t2rVOUpNWVFTknDt7K/YPfvADl5yc7Lxerxs/frzbuXOnbdEt4Ku2w/Hjx92ECRNcr169XKdOnVxGRoZ79NFH290fac39/JLc4sWLg31OnDjhHn/8cXfNNde4rl27urvuussdPHjQrugWcKntsHfvXjdmzBiXmJjovF6vu/baa93TTz/t/H6/beEX4PuAAAAmWv01IABA+0QAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAE/8Pqe1IHmS/198AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image = test_df.sample().to_numpy()[0]\n",
    "visualize_image(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to correctly classify image with expected label [3]\n",
      "Computing distances...\n",
      "Extract of distances: [1708.0737689  3351.91109667 1771.70482869 1350.70240986 2394.66135393\n",
      " 3093.35723769 1824.1450052  2242.46315466 1755.01709393 2738.13476659\n",
      " 2309.42503667 1086.67934553 2393.20245696 2255.14811044 1873.20046978]\n",
      "Found best distance-classes: [(1086.6793455293057, 1), (1185.898393624007, 1), (1350.7024098594036, 1), (1363.2193513884697, 4), (1366.8050336459842, 1), (1417.111498788998, 1), (1425.0242103206529, 1), (1426.5149841484315, 1), (1432.9448698397298, 1), (1443.8981958573117, 1), (1452.2547985804695, 1), (1465.4200762921191, 1), (1479.1903190597213, 6), (1491.1113305182816, 1), (1495.2982979994326, 1), (1502.5188850726636, 1), (1505.0465109092145, 1), (1508.3882126296267, 4), (1523.362727652216, 1), (1525.9066157534019, 1)]\n",
      "Most common occurences: [(1, 4), (4, 1)]\n",
      "Selecting 1\n"
     ]
    }
   ],
   "source": [
    "knnClassifier.classify_single_verbose(test_image, 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now do the whole test dataset once\n",
    "Test the model accuracy with different values of k, with or without condensation (reduction of the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying dataset with K=5\n",
      "Correct predictions: 885/1000, accuracy of 0.89%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Classifying dataset with K=5\")\n",
    "score = knnClassifier.classify_dataset(DistanceType.EUCLIDIAN, k=5)\n",
    "print(f\"Correct predictions: {score.success}/{score.total}, accuracy of {score.accuracy:.2}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy of your classification for K = {1, 3, 5, 10, 15} using the best distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_k(distance: DistanceType, optimize: bool) -> None:\n",
    "    knnClass = KnnClassifier(train_df, test_df)\n",
    "    \n",
    "    if optimize:\n",
    "        knnClass.optimize_dataset()\n",
    "\n",
    "    print(f\"Precomputing distances...\")\n",
    "    knnClass.precompute_distances(distance)\n",
    "    print(f\"Distance map complete\")\n",
    "\n",
    "    for k in [1, 3, 5, 10, 15]:\n",
    "        print(f\"Evaluating for k={k}...\")\n",
    "        score: Score = knnClass.classify_dataset(distance, k)\n",
    "        print(f\"For k={k}, score is {score.accuracy}% ({score.success}/{score.total})\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test all K on raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating distance EUCLIDIAN\n",
      "KNN prepared with 1000 data\n",
      "Precomputing distances...\n",
      "Distance map complete\n",
      "Evaluating for k=1...\n",
      "For k=1, score is 0.886% (886/1000)\n",
      "Evaluating for k=3...\n",
      "For k=3, score is 0.89% (890/1000)\n",
      "Evaluating for k=5...\n",
      "For k=5, score is 0.885% (885/1000)\n",
      "Evaluating for k=10...\n",
      "For k=10, score is 0.875% (875/1000)\n",
      "Evaluating for k=15...\n",
      "For k=15, score is 0.847% (847/1000)\n",
      "\n",
      "Evaluating distance MANHATTAN\n",
      "KNN prepared with 1000 data\n",
      "Precomputing distances...\n",
      "Distance map complete\n",
      "Evaluating for k=1...\n",
      "For k=1, score is 0.875% (875/1000)\n",
      "Evaluating for k=3...\n",
      "For k=3, score is 0.865% (865/1000)\n",
      "Evaluating for k=5...\n",
      "For k=5, score is 0.869% (869/1000)\n",
      "Evaluating for k=10...\n",
      "For k=10, score is 0.845% (845/1000)\n",
      "Evaluating for k=15...\n",
      "For k=15, score is 0.814% (814/1000)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for distance in DistanceType:\n",
    "    print(f\"Evaluating distance {distance.name}\")\n",
    "    evaluate_on_k(distance, False)\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test all K on condensated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating distance EUCLIDIAN\n",
      "KNN prepared with 1000 data\n",
      "Performing condensation from dataset of 1000 elements...\n",
      "Starting condensation\n",
      "New iteration of the working set\n",
      "Working set item  999/999\n",
      "Changes during iteration detected - 260 items switched to result set\n",
      "New iteration of the working set\n",
      "Working set item  739/739\n",
      "Changes during iteration detected - 60 items switched to result set\n",
      "New iteration of the working set\n",
      "Working set item  679/679\n",
      "Changes during iteration detected - 3 items switched to result set\n",
      "New iteration of the working set\n",
      "Working set item  676/676\n",
      "No change detected, condensation is over\n",
      "Dataset now has 324 elements\n",
      "Precomputing distances...\n",
      "Distance map complete\n",
      "Evaluating for k=1...\n",
      "For k=1, score is 0.834% (834/1000)\n",
      "Evaluating for k=3...\n",
      "For k=3, score is 0.854% (854/1000)\n",
      "Evaluating for k=5...\n",
      "For k=5, score is 0.849% (849/1000)\n",
      "Evaluating for k=10...\n",
      "For k=10, score is 0.844% (844/1000)\n",
      "Evaluating for k=15...\n",
      "For k=15, score is 0.816% (816/1000)\n",
      "\n",
      "Evaluating distance MANHATTAN\n",
      "KNN prepared with 1000 data\n",
      "Performing condensation from dataset of 1000 elements...\n",
      "Starting condensation\n",
      "New iteration of the working set\n",
      "Working set item  999/999\n",
      "Changes during iteration detected - 260 items switched to result set\n",
      "New iteration of the working set\n",
      "Working set item  739/739\n",
      "Changes during iteration detected - 60 items switched to result set\n",
      "New iteration of the working set\n",
      "Working set item  679/679\n",
      "Changes during iteration detected - 3 items switched to result set\n",
      "New iteration of the working set\n",
      "Working set item  676/676\n",
      "No change detected, condensation is over\n",
      "Dataset now has 324 elements\n",
      "Precomputing distances...\n",
      "Distance map complete\n",
      "Evaluating for k=1...\n",
      "For k=1, score is 0.828% (828/1000)\n",
      "Evaluating for k=3...\n",
      "For k=3, score is 0.838% (838/1000)\n",
      "Evaluating for k=5...\n",
      "For k=5, score is 0.852% (852/1000)\n",
      "Evaluating for k=10...\n",
      "For k=10, score is 0.833% (833/1000)\n",
      "Evaluating for k=15...\n",
      "For k=15, score is 0.803% (803/1000)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for distance in DistanceType:\n",
    "    print(f\"Evaluating distance {distance.name}\")\n",
    "    evaluate_on_k(distance, True)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e835e044c40c867db05629037020e41dc9de711a2d3844bbe40049c79692d69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
